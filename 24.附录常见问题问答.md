### 第4部分 附录
#### 附录A LLM常见问题解答

本节中的常见问题解答是使用LLM时出现的常见问题的汇总。这里提供的答案基于该领域众多研究人员和从业者的共同智慧。当读者在阅读中面临不确定性或障碍时，这些答案可以作为参考。

**问题1**：LLM已经了解了我所从事的领域，为什么还要添加一些基础知识呢？

**回答1**：是的，LLM具备领域知识，但这并不是全部。基础知识——也就是让LLM从基础概念中学习——可以提高它在特定情境中的效果，有助于从LLM那里获得更准确、更具体的响应。结合我们在第3章中使用聊天机器人示例介绍的思维链提示，可以增强系统的任务依赖性。因此，基础知识绝对是不可以跳过的步骤。

**问题2**：要部署一个闭源API，需要注意的主要事项是什么？

**回答2**：部署闭源API不仅仅是一个简单的复制粘贴工作。在用户选择API之前，比较不同模型的价格至关重要。此外，尽早预测成本也是明智之举。在之前介绍的案例中，笔者成功地通过一些积极的成本削减措施，将个人项目的成本从平均每天55美元削减到每天5美元。其中最大的改变是从GPT - 3切换到ChatGPT（当我第一次推出应用程序时，ChatGPT还不存在），并进行了一些提示调整，以减少生成令牌数量。大多数公司对生成令牌的收费高于输入/提示令牌的价格。因此，在部署闭源API时，务必注意成本方面的考量。

**问题3**：如果想部署一个开源模型，需要注意的主要事情是什么？

**回答3**：开源模型在部署前后都需要进行彻底的检查。

- **部署前**：
  - 寻找最佳超参数，如学习率等。
  - 定义有效的评估指标，不仅仅是损失函数。还记得我们如何使用Jaccard相似度得分来进行流派预测任务吗？
  - 小心数据交叉污染。如果在预测流派时不小心在生成的描述中包含了流派信息，相当于在给自己添麻烦。
- **部署后**：
  - 密切关注模型/数据的漂移。如果忽略了这些问题，随着时间的推移，可能会导致模型性能下降。
  - 不要对测试环节妥协。定期对模型进行测试，以确保其性能良好。

**问题4**：创建和微调自己的模型架构似乎很困难，可以做些什么使这个过程更容易？

**回答4**：创建和微调模型架构确实感觉非常困难。但通过实践并从失败中学习，情况会变得更好。笔者花了大量时间调整VQA模型或SAWYERM模型。读者在开始训练之前，需要花点时间决定自己使用的数据集和指标。读者肯定不希望在训练模型时发现自己使用了一个未经正确清理的数据集。

**问题5**：如果认为自己的模型很容易受到提示注入或偏离任务的影响，如何更正？

**回答5**：思维链的提示和基础知识在这里可以起到很大的帮助作用；确保模型不会偏离轨道。可以通过使用输入/输出验证来验证即时注入。回想一下我们是如何使用BART来检测攻击性内容的。相同的概念可以用于检测广泛的内容标签。提示链是防止提示注入的另一个方便工具。它以一种维护对话上下文和方向的方式链接提示。请确保在测试套件中运行测试以进行即时注入。

**问题6**：为什么没有讨论像LangChain这样的第三方LLM工具？

**回答6**：像LangChain这样的第三方工具在许多情况下肯定是有用的，但本书的重点是培养如何直接使用LLM的基本理解，对它们进行微调，并在不使用中介工具的情况下部署它们。基于这些原则建立基础，读者将掌握如何自信地使用任何LLM、开源模型或工具，并掌握必要的技能。

本书列出的知识和原则旨在使读者能够有效地利用自己在工作中可能遇到的任何LLM或第三方工具。通过了解LLM的细节，自己不仅能够熟练使用LangChain等工具，而且能够在知情的情况下决定哪种工具最适合特定的任务或项目。本质上，读者理解得越深，在语言模型这一广阔领域的应用和创新潜力就越大。

也就是说，第三方工具通常可以提供额外的易用性、预构建功能和简化的工作流程，从而加快开发和部署过程。例如，LangChain提供一种简化的方法来训练和部署语言模型。对于那些希望在更注重应用程序的环境中使用LLM的读者来说，这些工具绝对值得探索。

**问题7**：如何处理LLM中的过拟合或欠拟合？

**回答7**：当模型在训练数据上表现良好，但在看不见的或测试数据上表现不佳时，就会发生过拟合。当模型过于复杂或在训练数据中学习到噪声或随机波动时，通常会发生这种情况。像Dropout或L2正则化这样的正则化技术可以通过惩罚模型的复杂性来帮助防止过拟合。

当模型过于简单而无法捕捉数据中的基本模式时，就会出现欠拟合的情况。这可以通过增加模型的复杂性（例如，更多的层或单元）、使用更大或更多样化的数据集或运行更多周期（Epoch）的训练来缓解。

**问题8**：如何将LLM用于非英语语言？有什么独特的挑战吗？

**回答8**：LLM当然可以用于非英语语言。像mBERT（多语言BERT）和XLM（跨语言模型）这样的模型已经在多种语言上进行了训练，并且可以应用到某些语言处理任务。然而，模型的质量和表现可能因每种语言可用的训练数据的数量和质量而异。此外，由于不同语言的独特特征，如语序、形态或特殊字符的使用，可能会出现特定的挑战。

**问题9**：如何实现实时监控或日志记录，以便更好地了解已部署LLM的性能？ 

**回答9**：监控已部署模型的性能对于确保其按预期工作并尽早发现任何潜在问题至关重要。用户可以使用的工具如TensorBoard、Grafana和AWS CloudWatch来实时监控模型指标。此外，记录模型的响应和预测结果可以帮助用户解决一些问题，并了解模型在一段时间内的表现。最后，在存储此类数据时，请确保遵守所有相关的隐私法规和指南。

**问题10**：本书没有涉及哪些技术内容？

**回答10**：本书涵盖了广泛的主题，但语言模型和机器学习的许多方面我们都没有深入或根本没有涉及。LLM领域广阔且不断发展，我们的重点主要放在LLM独有的要素上。值得进一步探索的一些重要主题包括：

- **超参数调整**：Optuna是一个强大的开源Python库，可以帮助优化超参数。它采用了多种策略，如网格搜索，允许用户对模型进行微调以获得最大性能。

- **LLM中的偏见和公平性**：在讲解即时工程时简要谈到了管理LLM中偏见的重要性，但这个关键问题还有很多。确保人工智能模型的公平性，减少训练数据中存在的社会偏见的传播或放大，是一项持续的挑战。目前有很多工作正在进行，致力于通过技术来识别和减少机器学习模型（包括LLM）中的偏见。 

- **LLM的可解释性和可解释性**：随着LLM复杂性的增加，理解这些模型为什么以及如何得出某些预测或决策变得越来越重要。提高机器学习模型的可解释性成为一个广泛研究的领域。掌握这些技术可以帮助用户建立更透明、更可靠的模型。例如，LIME是一个Python库，它试图通过生成本地可信的解释来解决模型的可解释性问题。



所有这些主题虽然不是LLM独有的，但可以极大地提高用户有效和负责任地使用这些模型的能力。随着用户在这一领域的技能和知识的不断发展，会发现无数的创新机会，并产生有意义的影响。机器学习的世界是广阔的，学习之旅永无止境。尽管我们无法涵盖所有内容，但我们希望这本书能为读者提供一个坚实的基础，激发读者进一步探索和学习LLM领域的兴趣。



#### 附录B LLM术语表

为了确保语言上的一致性，本词汇表收集了读者可能遇到的关键人工智能（AI）/机器学习（ML）术语。无论读者是一个绝对的初学者，还是一个复习这些主题的人，这个术语表都是一个方便的参考，可以确保对这些术语有清晰的理解。请注意，这并不是本书按字母顺序列出的术语的详尽列表，而是按照我们在本书中所涵盖的顺序，收集了一些重要的术语和概念。

虽然人工智能和机器学习中有无数术语超出了本术语表的范围，但本列表旨在涵盖最常见的术语，特别是与大语言模型（LLM）相关的核心术语。随着这个领域的不断发展，我们用来描述它的语言也会不断发展。有了这个词汇表作为指南，读者将有一个坚实的基础来继续自己的学习之旅。

1. **Transformer架构**：2017年推出的Transformer架构（Transformer Architecture）是现代LLM的基础结构，它是一个序列到序列模型，包括两个主要组件：编码器和解码器。编码器负责处理原始文本，将其拆分为核心组件，并将其转换为向量，并利用注意力来学习上下文。解码器擅长通过使用改进的注意力机制预测下一个最佳令牌来生成文本。尽管Transformers及其变体（如BERT和GPT）很复杂，但它们已经彻底改变了自然语言处理（NLP）中文本的理解和生成。

2. **注意力机制**：在Transformer的原始论文*Attention is All You Need*中介绍，注意力机制（Attention Mechanism）允许LLM动态地关注输入序列的各部分，从而确定每部分在进行预测时的重要性。与早期平等处理所有输入的神经网络不同，注意力驱动的LLM已经彻底改变了预测准确性的情况。注意力机制主要负责使LLM学习或识别内部世界模型和人类可识别规则。一些研究表明，LLM可以通过训练来学习一套合成任务的规则，比如玩奥赛罗游戏，仅仅通过历史动作数据进行训练即可。这为探索LLM可以通过预培训和微调学习其他类型的“规则”开辟了新的途径。 

3. **大模型**：大模型（Large Language Model，LLM）是一种高级的自然语言处理（NLP）深度学习模型。它擅长大规模处理上下文语言，并预测特定语言中一系列词元的可能性。词元是语义的最小单位，可以是单词或者子单词，它在LLM中扮演着关键的输入角色。LLM可以分为自回归模型、自动编码模型或两者的组合。它们的共同特点是巨大的尺寸，这使得它们能够以高精度和最小的微调来执行复杂的语言任务，比如文本生成和分类。

4. **自回归语言模型**：自回归语言模型（Autoregressive Language Models）是一种基于序列的模型，它通过利用先前的词元来预测句子中的下一个词元。在Transformer模型中，自回归语言模型通常对应于解码器部分，并广泛应用于文本生成任务。GPT（Generative Pre - trained Transformer）是自回归语言模型的一个典型例子。

5. **自编码语言模型**：自编码语言模型（Autoencoding Language Models）的目标是从损坏的输入版本中重建原始句子，使其成为Transformer模型的编码器部分。通过在没有任何掩码的情况下访问完整的输入，自动编码语言模型能够生成整个句子的双向表示。自动编码语言模型可以通过微调适应各种任务，包括文本生成、句子分类或词元分类。BERT就是一个非常典型的例子。 

6. **迁移学习**：迁移学习（Transfer Learning）是一种机器学习技术，通过利用在一个任务中获得的知识来提升在另一个相关任务中的表现。在LLM中，迁移学习意味着使用少量的特定任务数据来微调已经预先训练好的LLM，以适应特定任务，例如文本分类或文本生成。这样的迁移学习方法能够节省培训过程中的时间和资源。

7. **提示工程**：提示工程（Prompt Engineering）的关键在于设计有效的提示，即作为LLM的输入，以清晰地传达任务要求，从而产生准确而有益的输出。这是一门需要深刻理解语言微妙之处、涉及的特定领域知识以及LLM在使用中的功能和限制的技能。 

8. **对齐**：对齐（Alignment）的概念涉及语言模型以符合用户期望的方式理解提示并对其做出反应的程度。传统的语言模型只根据上下文来预测下一个单词或序列，不具备特定指令或提示的能力，这限制了它们的应用范围。然而，一些先进的模型却具备了高级的对齐功能，例如AI的RLAIF和OpenAI的RLHF，这些模型在快速响应能力和问答与语言翻译等应用中的实用性方面有所提升。 

9. **从人类的反馈中强化学习**：从人类的反馈中强化学习（Reinforcement Learning from Human Feedback，RLHF）是一种用于机器学习的对齐技术，涉及基于人类监督者的反馈来训练人工智能模型。人类根据模型的反馈向模型提供奖励或惩罚，从而有效地指导其学习过程。其目的是完善模型的行为，使其反应更接近人类的期望和需求。 

10. **从人工智能的反馈中强化学习**：从人工智能的反馈中强化学习（Reinforcement Learning from AI Feedback，RLAIF）是一种模型对齐方法，其中AI用于在模型训练期间向其提供反馈。通过使用人工智能来评估和提供奖励或惩罚，RLAIF旨在优化模型的性能，并使其响应与预期结果更加一致，从而增强其在特定任务中的效用。 

11. **语料库**：语料库（Corpora）是文本数据集，类似于研究人员使用的资源材料。语料库的质量和数量对于LLM的学习效果至关重要。 

12. **微调**：在微调（Fine - Tuning）步骤中，LLM一旦完成预训练，就会在较小的特定任务数据集上进行训练，以优化其任务参数。通过利用预先训练的语言知识，LLM能够提高其在特定任务上的准确性。微调过程显著提升了LLM在特定领域和任务上的性能，使其能够快速适应各种NLP应用程序。 


13. **带标签的数据**：带标签的数据（Labeled Data）由已经使用一个或多个标签进行注释的数据元素或数据样本组成，这些标签通常表示相应数据元素的正确输出或答案。带标签的数据在特定任务中起着重要的作用。在监督学习的背景下，带标签的数据是学习过程的基础。通过使用带标签的数据，包括LLM在内的模型能够学习正确的模式和关联。模型通过观察输入数据和对应的标签，逐渐理解输入和输出之间的关系，并学会根据输入预测正确的输出。

带标签的数据通常需要通过人工注释来完成，注释者会检查原始数据并为其分配适当的标签。然而，标注过程很容易受到注释者的理解、解释和主观偏见的影响，从而导致标注数据中存在偏见的可能性。这种偏见可能会在经过训练的模型中得到反映，强调了仔细控制标注过程以最大限度地减少偏差的重要性。 

14. **超参数**：超参数（Hyperparameters）就像在烘焙时调整温度和计时器一样，超参数是模型训练过程中可以调整的设置。就像在烘焙过程中，不同的温度和时间设置会对最终的烘焙结果产生显著影响一样，超参数的选择也会对模型的性能和输出结果产生重要影响。 

15. **学习率**：学习率（Learning Rate）在模型学习过程中类似于步长，它决定了每次参数更新的幅度。就像在行走时，较小的步长意味着每次迈出小步，导致学习过程较为缓慢，但可能更准确。而较大的步长则相当于迈出较大的跨度，学习速度更快，但可能会错过最佳解决方案。 

16. **批大小**：批大小（Batch Size）表示模型一次从多少个训练示例中学习。就像在学习过程中，较大的批大小意味着每次从训练数据中取出更多的示例进行学习，这可能会导致学习过程更快，但可能不那么详细。而较小的批大小则相反，每次从训练数据中取出较少的示例进行学习，这可能导致学习过程较慢，但可能会得到更详细的理解。 

17. **训练周期**：重读一本书以更好地理解它，并从一些段落中找出更多的意义，确实可以帮助我们更深入地理解图书的内容。在训练过程中，我们通过多次迭代将训练数据完整地传递给模型，就像重读一本书一样。每个训练周期（Training Epochs）模型都有机会改进并深入理解训练数据中的模式和特征。就像重复阅读一本书可以让我们从中获得更多的理解和洞察力一样，多个训练周期可以让模型更好地学习和捕捉数据集中的信息。 

18. **评估指标**：评估指标（Evaluation Metrics）可以被视为衡量模型表现的记分卡，就像我们对学生的表现进行评分一样。不同的任务可能需要不同的度量方式，我们对学生的评分也需要根据不同的标准进行评估，例如出勤率、作业完成情况、考试成绩等。 

19. **增量/在线学习**：增量/在线学习（Incremental/Online Learning）是指在机器学习方法中，模型顺序地从数据中学习，并随着时间的推移改进其预测能力。将其类比为在职培训确实能够形象地描述这个过程：随着新的体验或数据的出现，系统不断学习和适应。 

20. **过拟合**：过拟合（Overfitting）是指模型在训练数据上学习得非常好，以至于在未见过的或测试数据上表现不佳。这种情况下，模型实际上记住了训练数据中的噪声或随机波动，但并未能将学到的知识推广到新的数据上。对于LLM而言，如果模型过度适应了训练数据中的具体情况，可能会发生过拟合，从而失去对于看不见的提示生成合理响应的能力。这意味着模型可能会生成过于具体或狭义的响应，无法正确地处理新的提示。 

21. **欠拟合**：欠拟合（Underfitting）指的是模型过于简单，无法捕捉训练数据中的基本模式，导致在训练和测试数据上的性能表现较差。当模型的复杂性不足或者训练时间不够长时，通常会发生欠拟合的情况。在语言模型的背景下，如果模型未能很好地掌握训练数据的上下文或微妙之处，那么可能会出现欠拟合现象。这可能导致模型输出过于笼统、偏离主题或

对提示毫无意义。



#### 附录C LLM应用架构

本附录是多个表格，其中展示LLM应用程序的不同原型以及用户应该考虑的相关因素。附表C - 1~附表C - 6是用户应用和操作这些模型的无数方法的简明指南，以及必须注意的潜在陷阱和实施策略。

|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|客户服务，个人助理，娱乐，医疗保健，教育等|对话数据集，特定领域的知识库|机器人可能无法反映预期的角色、语义误解的风险、对复杂查询的错误响应|在设计阶段定义和固定机器人的角色，使用语义搜索进行准确的信息检索|
|**附表C - 2 闭源LLM的微调**|
|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|为文本生成、摘要、翻译等特定任务定制语言模型|特定领域数据集、微调指南和目标任务评估数据集|对特定数据的过度拟合、泛化能力的丧失、意外输出或行为的可能性。无法检查基础模型|仔细选择微调数据集，定期验证和测试模型输出，应用诸如差分隐私等技术来提高健壮性，并添加后处理步骤以过滤出意外输出|
|**附表C - 3 微调开源LLM**|
|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|文本分类、命名实体识别、情感分析、问答等|特定领域数据集、目标任务评估数据集|对特定数据的过度拟合，潜在的泛化损失，计算资源的限制|选择合适的数据集，使用早停和正则化技术来避免过拟合，采用分布式训练来处理计算资源限制。尝试各种模型架构以获得最佳性能|
|**附表C - 4 微调双编码器以学习新的嵌入**|
|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|语义相似度、句子相似度、信息检索、文档聚类等|具有相似性得分或其他关系信息的文本对或文本集|嵌入可能无法捕捉某些术语或上下文的细微差别。由于高维数而难以调整|正确选择相似性度量（例如，余弦相似度或欧几里得距离）。将注释数据集用于特定任务。应用降维技术以促进调整和可视化|
|**附表C - 5 微调LLM使其遵循RLHF和RLAIF指令**|
|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|面向任务的对话系统、游戏机器人、引导式自动化、程序任务等|带有指令和相应正确操作或结果的数据集，人类对模型性能的反馈|对指令的误解、对训练集的过度拟合、强化学习中的稀疏奖励信号|利用不同的训练集来捕捉各种指令格式，通过反馈循环进行微调以提高指令跟踪能力，为强化学习设计稳健的奖励函数|
|**附表C - 6 开放式问答**|
|应用|数据|潜在的陷阱|实施策略|
| ---- | ---- | ---- | ---- |
|问答系统、教育工具、知识提取、信息检索等|包含问题、答案和相关参考文件或“开放式书籍”的数据集|在问答过程中与“开放式书籍”断开连接，难以将外部知识与内部表征相协调和整合，可能产生不相关或错误的反应|在提供的“开放式书籍”中为模型打下基础，实施思维链提示| 
