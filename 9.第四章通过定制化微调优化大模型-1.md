### 第2部分 充分挖掘大模型的潜力
#### 第4章 通过定制化微调优化大模型
### 4.1 简介

到目前为止，我们只是直接使用了开源和闭源的LLM，并未做任何修改。我们依靠Transformer的注意力机制以及其计算速度，相对容易地解决了一些非常复杂的问题，但这些远远不够。

本章将深入研究微调大模型的世界，以释放其全部潜力。微调更新现成的模型，并使其能够得到更高质量的结果；它可以节省词元，并且通常可以降低延时请求。虽然GPT类LLM在大量文本数据上的预训练能够实现令人印象深刻的小样本学习功能，但微调能更进一步地在大量样本上优化模型，从而在各种任务中实现卓越的性能。

从长远来看，使用微调模型进行推理非常具有成本优势，特别是在使用较小的模型时。例如，OpenAI的微调ADA模型（只有3.5亿个参数），每1000个词元的成本仅为0.0016美元，而ChatGPT（15亿个参数）的成本为0.002美元，DaVinci（1750亿个参数）的成本为0.002美元。随着时间的推移，使用微调模型的成本更具吸引力，如图4.1所示。

本章的目标是指导读者完成微调过程，从准备训练数据开始，训练一个新的或已有的微调模型，以及讲解如何将微调模型整合到真实的应用中。这是一个很大的话题，所以必须假设一些大的环节，例如标记数据已经处理好了。在许多复杂和特定的任务中，标记数据可能是一笔巨大的开支，但现在我们假设数据已经打好标签。有关如何处理这些情况的更多信息，请随时查看笔者在特征工程和数据清洗方面的其他内容。

了解微调并掌握其技术特点，用户才能够充分利用LLM的力量，为自己的特定需求创建量身定制的解决方案。

![image](https://github.com/user-attachments/assets/925c91e4-7b2f-413b-969a-d9aaf879e2c4)

### 4.2 迁移学习与微调入门

微调的思想源于迁移学习。迁移学习是一种利用预训练的模型在现有知识的基础上为新任务或新领域进行重新构建的技术。在使用LLM的情况下，这将涉及利用预训练把包括语法和一般知识在内的通用语言理解任务转移到特定领域。然而，预训练可能不足以理解某些封闭或专业主题的细微差别，例如公司的法律结构或指导方针。

微调是一种特定的迁移学习形式，它调整预训练模型的参数，以更好地适应“下游”的目标任务。通过微调，LLM可以从自定义样本中学习，并在生成结果的相关性和准确性方面表现更有效。

#### 4.2.1 微调过程的解释

微调深度学习模型涉及更新模型的参数，以提高其在特定任务或数据集上的性能。

- **训练集**：用于训练模型的样本集合。模型基于训练样本调整其参数来学习并识别数据中的模式和关系。

- **验证集**：用于在训练期间评估模型性能的单独的样本集合。 

- **测试集**：与训练集和验证集不交叉的第三批样本集合，用于评估在训练过程完成后模型的最终性能。测试集提供对模型泛化到新的、未见过的数据的最终、无偏估计。 

- **损失函数**：量化模型预测值与实际目标值之间差异的函数，作为误差度量评估模型的性能并指导优化过程。在训练过程中，目标是使损失函数最小化以实现更好的预测。


微调过程可分为以下几个步骤。

（1）**收集标记数据**：微调的第一步是收集与目标任务或领域相关样本的训练、验证和测试数据集。标记数据可以指导模型学习特定任务的模式和关系。例如，如果目标是微调一个用于情感分类的模型（第一个例子），数据集应该包含文本样本以及它们各自的情感标签，如正面、负面或中性。

（2）**超参数选择**：微调涉及调整影响学习过程的超参数，例如学习率、批处理大小、权重和迭代次数。

学习率决定模型权重更新的步长，而批量大小是指单个更新中使用的训练样本的数量。迭代次数表示模型在整个训练数据集上迭代的次数。正确设置这些超参数可以显著提升模型的效果，并有助于防止过拟合（模型更多地学习了训练集中的噪声而不是信号）和欠拟合（模型未能捕获数据的底层结构）等问题。

（3）**模型自适应**：一旦设置了样本数据和超参数，模型需要适应目标任务。这涉及修改模型的架构，例如添加自定义层或更改输出结构，以更好地适应目标任务。例如，虽然BERT的架构无法按原样执行序列分类，但我们可以对其进行非常轻微的修改以执行此任务。在案例研究中，OpenAI将代为处理，所以不需要我们做修改。不管怎样，我们必须在后面的章节中处理这个问题。

（4）**评估和迭代**：微调过程完成后，则必须在单独留出的验证集上评估模型的效果，以确保它能够很好地泛化到未见过的数据。可以使用准确率、F1分数或平均绝对误差（MAE）进行评估，根据任务的不同，如果效果不令人满意，可能需要调整超参数或数据集，然后重新训练模型。

（5）**模型部署和后续重训**：一旦模型经过微调而且用户满意其性能，就需要将其集成到现有的架构中，并且使其能够处理任何异常以及收集用户反馈。这样做将增加用户的数据集规模，方便后续的重训。


该过程如图4.2所示。数据集被分为训练集、验证集和测试集。训练集用于更新模型的权重，而验证集用于在训练期间评估模型。最终模型针对测试集进行测试，并根据一组标准进行评估。如果模型通过所有这些测试，则将其用于生产并持续监控效果，以便进一步迭代。请注意，该过程可能需要多次迭代，并仔细斟酌超参数、数据质量和模型架构，以实现预期结果。

![image](https://github.com/user-attachments/assets/3a829453-8cd0-4789-b23e-ce6dfd15db4a)


#### 4.2.2 闭源预训练模型作为基础模型
预训练的LLM在迁移学习和微调中具有至关重要的作用，为通用语言理解和知识提供基础。这个基础允许模型高效地适应特定的任务和领域，减少对大量训练资源和数据的需求。
本章重点介绍使用OpenAI的基础设施微调LLM，该基础设施是专门为促进这一过程而设计的。OpenAI开发了工具和资源，使研究人员和开发人员更容易根据他们的特定需求微调较小的模型，如Ada和Babbage。该基础设施提供一种简化的微调方法，允许用户有效地将预训练模型适配到各种任务和领域。
利用OpenAI的基础设施进行微调具有以下优势。
- **访问强大的预训练模型**：例如GPT - 3这种已经在各种各样的数据集上训练过的模型。 
- **相对友好的接口**：简化了不同专业水平的人的微调过程。 
- **一系列工具和资源**：帮助用户优化微调过程，例如超参数选择指南、自定义样本的提示以及模型评估的建议。 

这种精简的过程节省了时间和资源，同时确保在能够开发中构建高质量模型，并生成准确的结果。接下来将深入进行开源模型的微调，它的优缺点将在第6 - 9章中阐述。



### 4.3 OpenAI微调API概览
GPT - 3微调API为开发人员提供了访问最先进的LLM的权限。此API提供了一系列微调功能，允许用户调整模型以适用于特定任务、语言和领域。本节讲解GPT - 3微调API的关键功能、支持的方法以及成功微调模型的最佳实践。
#### 4.3.1 GPT - 3微调API
GPT - 3微调API就像一个宝库，充满了强大的功能，让定制模型变得轻而易举。像是一个一站式商店，从支持各种微调功能到提供一系列方法，还可以根据用户的特定任务、语言或领域定制模型。本节旨在揭示GPT - 3微调API的秘密，重点介绍使其成为宝贵资源的工具和技术。
#### 4.3.2 案例学习：亚马逊评论情感分类

第一个案例研究将使用amazon_reviews_multi数据集，如图4.3所示。是amazon_reviews_multi数据集的一个片段，显示了输入的上下文（评论标题和正文）和响应（用户试图预测的目标——评论者给出的评分）。该数据集是来自亚马逊的商品评论，涵盖多种商品类别和语言（英语、日语、德语、法语、中文和西班牙语）。数据集中的每条评论都附有一个1~5星的评分，1星为最低评分，5星为最高评分。我们在这个案例研究中的目标是通过微调来自OpenAI的预训练模型，对这些评论进行情感分类，使其能够预测评论中给出的评分。

![image](https://github.com/user-attachments/assets/eab167de-09f3-4f86-bbf3-5c43b0e0b5bc)


在这一轮微调中，我们将关注数据集中的三列：

- **review_title**：评论的文本标题。 
- **review_body**：评论的文本正文。 
- **stars**：一个1~5的整数。 

我们的目标是使用评论标题和正文的内容预测给出的评分。
#### 4.3.3 数据指南和最佳实践
一般来说，在选择数据进行微调时需要考虑以下几个因素。
- **数据质量**：确保用于微调的数据具有高质量，没有噪声，并且能够准确代表目标域或任务。这将使模型能够有效地根据训练样本进行学习。 
- **数据多样性**：确保数据集是多样化的，涵盖广泛的场景，以帮助模型在不同情况下能很好地泛化。 
- **数据平衡**：保持不同任务和领域之间样本的平衡分布有助于防止模型过拟合，并降低模型的偏差。对于不平衡的数据集，可以通过对数量较多的类别进行欠采样、对数量较少的类别进行过采样或添加合成数据来实现。由于该数据集经过精心策划，因此情感类型得到了完美的平衡。读者可以在本书的代码库中查看一个更难的例子，尝试对非常不平衡的类别分类任务进行分类。 
- **数据量**：确定微调模型所需的总数据量。通常，较大的LLM需要更广泛的数据来有效地捕捉和学习各种模式，但如果LLM在足够相似的数据上预先训练过，则可以使用较小的数据集。所需的确切数据量可能因目标任务的复杂性而异。任何数据集不仅应该广泛，而且应该多样，并代表问题空间，以避免潜在的偏见，确保在广泛的输入范围内具有稳健的性能。虽然使用大量训练数据可以帮助提高模型性能，但也增加了模型训练和微调所需的计算资源。需要在特定项目要求和资源背景下做出权衡。 

### 4.4 使用OpenAI CLI实现自定义数据微调
在进行微调之前，需要根据API的要求清理和格式化数据，包括以下步骤。
- **删除重复项**：为了确保最高的数据质量，首先要从数据集中删除任何重复的评论。这将防止模型过度拟合某些样本，并提高其泛化新数据的能力。 
- **拆分数据**：将数据集分为训练集、验证集和测试集，每个部分需要保证样本的随机分布。如有必要，可考虑使用分层抽样，以确保每个数据集包含一定比例的、不同类型的数据，从而保证数据集整体分布均匀。 
- **对训练数据进行打散**：在微调之前对训练数据进行打散有助于避免学习过程中的偏差，因为这样可以确保模型以随机顺序加载样本，从而降低样本顺序学习模式的风险。还可以通过在训练的每个阶段将模型暴露给更多样化的实例来提高模型的泛化能力，这也有助于防止过拟合。因为模型不太可能记住训练样本，而是将重点放在学习底层模式上。图4.4显示了打散训练数据的好处。未打散的数据会导致糟糕的训练结果，会使模型有可能对特定批次的数据进行过度拟合，并降低响应的整体质量。顶部两幅图表示在未打散的训练数据上训练的模型，与在打散的数据（底部两幅图）上训练的模型相比，其准确率非常糟糕。理想情况下，数据将在每次遍历之前进行打散，以尽可能减少模型对数据的过拟合。 

- **创建OpenAI JSONL格式**：OpenAI的API希望训练数据为JSONL（换行符分隔的JSON）格式。对于训练集和验证集中的每个样本，创建一个包含两个字段的JSON对象：prompt（提示）和completion（响应）。prompt字段应包含评论文本，而completion字段应存储相应的情感标签（星级评分）。将这些JSON对象用换行符分隔，并保存在单独的文件中，用于训练集和验证集。

![image](https://github.com/user-attachments/assets/6ed05088-9069-429c-8985-d1b2d5fc69cd)


对于数据集中的响应词元，应该确保在类别标签之前出现一个前导空格，因为这使模型能够知道应该生成一个新的词元。此外，在为微调过程准备提示词时，没有必要包含小样本案例，因为模型已经在特定任务的数据上进行了微调。相反，可提供一个提示，包括评论文本和任何必要的上下文，后面是一个后缀（例如，“Sentiment:”没有后随空格或“\n\n###\n\n”，如图4.5所示），表示所需的输出格式。图4.5是提供给OpenAI的训练数据的单个JSONL样本。每个JSON都有一个提示词键，表示模型的输入，不包括任何小样本、指令或其他数据，还有一个响应键，表示用户希望模型输出的内容——在这种情况下，是一个单一的分类词元。在这个例子中，用户对产品评分为1星。图4.5显示了JSONL文件的一行样本。

对于输入数据，笔者将评论的标题和正文连接起来作为单一输入。因为标题表达的观点更直接，而正文包含更多与评分相关的细节。请读者随意探索将文本字段组合在一起的不同方法。我们将在以后的案例研究中进一步探讨这个主题，以及为单个文本输入设置格式化的其他方法。

![image](https://github.com/user-attachments/assets/7490e868-c2dd-47a9-b664-0667586958f5)


程序清单4.1加载了Amazon Reviews数据集，并将训练子集转换为pandas DataFrame。然后使用自定义的prepare_df_for_openai函数对DataFrame进行预处理，该函数将评论标题和评论正文组合成一个提示词，创建新的一列，并过滤DataFrame，使其仅包含英语评论。最后，根据prompt列删除重复行，并返回仅包含prompt和completion列的DataFrame。



**程序清单4.1：为情感训练数据生成JSONL文件**

```python
from datasets import load_dataset
import pandas as pd

# 加载亚马逊评论的多语言数据集
dataset = load_dataset("amazon_reviews_multi", "all_languages")
# 把数据集的训练子集转换为pandas的DataFrame
training_df = pd.DataFrame(dataset['train'])

def prepare_df_for_openai(df):
    # 把review_title和review_body列组合在一起，并且在末尾增加后缀"\n\n###\n\n"创建prompt列
    df['prompt'] = df['review_title'] + '\n\n' + df['review_body'] + '\n\n###\n\n'
    # 通过在stars数据前加一个空格创建一个新的completion列
    df['completion'] = ' ' + df[stars]
    # 过滤DataFrame，只包括language等于'en'的行
    english_df = df[df['language'] == 'en']
    # 基于prompt列删除重复行
    english_df.drop_duplicates(subset = ['prompt'], inplace = True)
    # 返回只有prompt和completion列的过滤后的DataFrame
    return english_df[['prompt', 'completion']].sample(len(english_df))

english_training_df = prepare_df_for_openai(training_df)
# 把prompts和completions输出到JSONL文件中
english_training_df.to_json("amazon - english - full - train - sentiment.jsonl", orient ='records', lines = True)
```
我们将对数据集的验证集和预留的测试集进行类似的处理，以对微调后的模型进行最终测试。在这种情况下，程序清单4.1只过滤英语，但读者可以自由地通过混合更多语言来训练自己的模型。笔者只是想以高效的成本快速获得一些结果。

### 4.5 设置OpenAI CLI
OpenAI CLI（命令行界面）简化了微调以及与API交互的过程。CLI允许用户提交微调请求，监控训练进度，以及管理自己的模型，所有这些都可以通过命令行完成。在继续进行微调过程之前，必须确保已使用API密钥安装并配置了OpenAI CLI。

要安装OpenAI CLI，可以使用Python包管理器pip。首先，确保使用的计算机系统中安装了Python 3.6或更高版本。然后按照以下步骤操作。

（1）打开终端（在macOS或Linux操作系统中）或命令行（在Windows操作系统中）。

（2）运行以下命令安装openai包：
```
pip install openai
```
此命令会安装包含CLI的OpenAI Python包。
（3）要验证安装是否成功，请运行以下命令：
```
openai --version
```
此命令应显示已安装的OpenAI CLI的版本号。

在使用OpenAI CLI之前，需要使用API密钥对其进行配置。为此，要将OPENAI_API_KEY环境变量设置为API的密匙。读者可以在OpenAI账户看板中找到API密钥。下面讲解超参数选择与优化。


创建了JSONL文档并安装了OpenAI CLI后，就可以选择超参数了，以下是关键超参数及其定义列表。

- **学习率**：学习率决定了模型在优化过程中采取的步骤大小。较小的学习率会导致较慢的收敛速度，但是潜在的精度更高。而更大的学习率加快了训练速度，但可能会导致模型跳过最佳解决方案。 

- **批大小**：批大小是指训练的一次更新中使用的训练样例的数量。较大的批大小可以使模型具有更稳定的梯度和更快的训练速度，而较小的批大小可能使模型具有更高的精度，但收敛速度较慢。 

- **训练周期**：一个周期是指完整地通过整个训练数据集。训练周期的数量决定了模型对数据进行迭代的次数，从而使其能够学习和优化其参数。 


OpenAI已经做了很多工作来为大多数情况找到最佳设置，因此我们将依靠它的建议进行第一次尝试。我们唯一要改变的是训练1个周期而不是默认的4个周期。这样做是因为我们想在投入更多时间和金钱之前先看看性能如何。尝试不同的参数值或使用网格搜索等技术将帮助用户找到任务和数据集

### 4.6 LLM微调实践
下面开始第一次微调。程序清单4.2调用OpenAI来训练一个Ada模型（最快、最便宜、最弱），在训练和验证数据上训练1个周期。 
