### 《快速部署大模型：LLM策略与实践（基于ChatGPT等大语言模型）》
- **封面**

Pearson

快速部署大模型

LLM策略与实践

（基于ChatGPT等大语言模型）

[美] 斯楠·奥兹德米尔（Sinan Ozdemir） ○ 著

姚普 白涛 卜崇宇 王蜀洪 ○ 译

Quick Start Guide to

Large Language Models

Strategies and Best Practices

for Using ChatGPT and Other LLMs

清华大学出版社



- **作者简介**

斯楠·奥兹德米尔（Sinan Ozdemir）拥有数学硕士学位，是一位成功的人工智能企业家和风险投资顾问。在担任约翰·霍普金斯大学讲师期间，首次涉足数据科学和机器学习，发明了人工智能领域的多项专利。

后来创立了Kylie.ai——一个融合了对话式人工智能和机器人能力的创新平台。Kylie.ai很快就因其独特的价值主张而受到关注，最终被收购。在此期间，斯楠·奥兹德米尔开始创作大量关于数据科学、人工智能和机器学习的作品。



- **译者简介**

姚普 中国科学院大学博士，现任京东资深算法工程师，多年从事算法设计与开发、算法框架引擎开发、算法产品化开发，在图算法和大模型领域深耕多年，《图深度学习从理论到实践》作者。



- **译者序**

人工智能作为一种革新性、颠覆性技术，正在深刻改变着人类的生产生活方式和思维方式，并对社会经济发展产生了重大而深远的影响。作为人工智能领域的前沿技术之一，大语言模型（LLM）的出现正逐步改变人类对语言、沟通乃至认知的理解。这些模型通过不断迭代与升级，不仅在自然语言处理领域取得了革命性突破，更是将人工智能的应用推向了一个崭新的高度。从简单的问答到复杂的文字生成，从初级的情感理解到撰写具有丰富感情色彩的文章，LLM有着令人着迷的魔力，并驱使着人们不断探索与实践，发现更多令人兴奋的秘密。

一本既包含大模型原理，又包含大量代码实践，内容通俗易懂的书籍并不多见。译者团队阅读本书英文原稿后，颇感兴趣，希望把本书的精神与知识分享给广大想入门人工智能的读者朋友们，帮助程序员和非程序员学习大语言模型及其应用策略。

在内容上，本书覆盖了大模型基本结构概述、提示词工程、大模型的微调、强化学习与人类反馈等基础理论知识，也包含采用大模型制作检索引擎、推荐系统、文图检索等入门应用实践，还介绍了大模型应用于商业生产时，开源与闭源的策略选择等，能够帮助广大读者对大模型的相关知识有一个快速的认知，进而帮助读者快速融入人工智能时代。

本书的翻译工作由姚普博士及其团队共同完成。由于英文与中文环境的表达方式的差异，翻译出易于阅读的译本并不容易。在这里特别感谢一起审稿的朋友，胡晓花、李树泉、姚灿、于流洋、张磊、蔡婕、武自伟、李思莹、杨科大、徐威、侯林芳、钟厚、王启立、陈希、张银晗、刘斌、张芷芊、林增跃、王荟、王军等。读者在阅读过程中有任何问题，可关注“松鼠NLP”公众号（见下方二维码）与姚普博士联系。

最后，我们要感谢帮助本书出版的编辑人员、审校人员和其他工作人员。没有你们的帮助，本书将无法面市。



- **推荐序**

在过去五年中，大语言模型（LLM）的使用一直在增长，随着OpenAI的ChatGPT的发布，人们对它的兴趣开始激增。人工智能聊天机器人展示了LLM的力量，并推出了一个易于使用的界面，使各行各业的人们都能利用这一变革性的工具。现在，自然语言处理（NLP）这个子集已经成为机器学习中最受关注的领域之一，许多人希望将其纳入自己的产品中。这项技术实际上更接近于人类的智慧，尽管它只是使用概率预测得到的模型。

本书很好地概括了LLM的概念以及如何实际使用，无论是对于程序员还是非程序员都适用。通过解释、可视化表示和实用代码示例的结合，使阅读变得引人入胜且简单，鼓励读者不断往下阅读。Sinan以引人入胜的方式阐述了许多主题，使其成为了解LLM、LLM的能力以及如何利用它们以获得最佳结果的最佳资源之一。

Sinan在大模型的诸多方面均有涉猎，为读者提供了有效使用LLM所需的所有信息。本书从LLM在NLP中的地位以及Transformer和编码器的解释开始，以易于理解的方式讲解迁移学习、微调、嵌入、注意力和词元化，并涵盖了LLM的许多方面，包括开源和商业选项之间的权衡，如何利用向量数据库（这本身就是一个非常流行的话题），用Fast API编写自己的API，创建嵌入，以及将LLM投入生产，这对于任何类型的机器学习项目都是具有挑战性的。

本书的很大一部分是对使用可视化界面（如ChatGPT）和编程接口的介绍。Sinan提供了有用的Python代码，这些代码很容易理解，并且清楚地说明了正在进行的工作。Sinan对提示工程的讲解阐明了如何从LLM中获得更好的结果，还演示了如何在可视化界面中的Python OpenAI库获取这些提示。

本书极具变革性，我忍不住想用ChatGPT来写这篇推荐序，以展示我所学到的一切。事实上它写得如此好，内容丰富，引人入胜。虽然我觉得这样做是可以的，但我仍然亲自写了这篇序言，以我所知道的最真诚的个人方式表达我对LLM的想法和体验。除了最后一句的最后一部分，那是ChatGPT写的，只是因为它可以。

对于希望了解LLM任何方面中任何一个的读者来说，本书是十分合适的。它将帮助读者理解模型，以及如何在日常生活中有效地使用它们。也许最重要的是，读者会享受阅读的旅程。

——Jared Lander，Series编辑



- **前言**

笔者原来是一名理论数学家、大学讲师，后来成为人工智能爱好者，再后来成为成功的创业公司创始人、人工智能教科书作者、风险投资顾问。今天，笔者还可以作为导游，带读者参观LLM工程和应用这个巨大的知识博物馆。本书的编写有两个目的：一是揭开LLM领域的神秘面纱，二是为读者提供实用的知识，使读者能够开始实验、编码和构建LLM。

与在课堂上大多数教授的讲解不同，本书并不是要用复杂的术语向读者灌输，相反，本书的目的是使复杂的概念易于理解、容易与常识关联起来，更重要的是具有实用性。

坦率地说，于笔者而言，本书内容已经相当充分。笔者想给读者一些关于如何阅读本书的提示，多次阅读本书，确保自己从本书中获得自己所需的知识。



### 读者人群和预备知识

本书是为谁准备的？答案很简单：任何对LLM充满好奇心的人，有意愿的程序员，不懈的学习者。无论你在机器学习领域已有见解，还是正准备开始学习相关知识，本书都是你的指南，是为你导航LLM领域的地图。

为了最大限度地利用这段旅程，拥有一些机器学习和Python方面的经验将是非常有益的。这并不是说没有它们你将无法继续，而是没有这些工具，阅读的过程可能有点波折。如果你准备边读边学习，那也很好。我们将探索的一些概念并不一定全部需要大量的编码，但大多数是需要的。

在本书中，笔者试图在深入的理论理解和实际的实践技能之间找到平衡。书中每章都充满了类比，将复杂的事物变得简单，并配以代码片段，使概念更加生动。本质上，笔者是将这本书作为LLM讲师+助教，旨在简化和揭开LLM引人入胜的神秘面纱，而不是向读者灌输学术术语。笔者希望读者在结束每一章时能更清楚地理解主题，并了解如何将其应用于真实世界中的场景。



### 如何阅读本书

如前所述，如果读者有一些机器学习的经验，会发现这个旅程比没有经验的人稍微容易一些。尽管如此，这条路对任何可以用Python编码并准备学习的人都是开放的。本书可以满足不同阅读层次的读者需求，取决于每个人的背景、目标和可用的时间。依据个人喜好，读者可以深入实践部分，尝试代码并调整模型，或者可以参与理论部分，在没有编写一行代码的情况下深入理解LLM如何工作。

需要注意的是，本书每一章都建立在之前的章节上。读者在前面部分中获得的知识和技能将成为后续部分的基础。面临的挑战是学习过程的一部分，读者可能会困惑、沮丧，有时甚至陷入困境。当笔者为本书开发可视化问答（VQA）系统时，曾遇到了多次失败。模型会输出无意义的内容，一遍又一遍地重复相同的短语。但是，经过无数次迭代之后，它开始生成有意义的输出。胜利的那一刻，取得突破的喜悦，让之前每一次失败的尝试都有价值。本书将为读者提供类似的挑战，使读者体验类似的胜利喜悦。



### 本书总览

本书分为以下四部分。

**第1部分：大模型介绍**

- 第1章：本章对LLM的领域进行概述。包括基本知识：它们是什么、如何工作、为何重要，读完本章，读者会有一个坚实的基础来理解本书的其余部分。

- 第2章：在第1章的基础上，深入讲解LLM如何用于其最具影响力的应用之一——语义搜索。本章将致力于创建一个能够理解查询含义的搜索系统，而不仅仅是匹配关键字。

- 第3章：科学且具有艺术性的提示指令对充分使用大模型的能力十分重要。第3章提供提示工程的实用介绍，以及充分利用LLM的指导方针和技术。



**第2部分：充分挖掘大模型的潜力**

- 第4章：在LLM中的既有模型并不适合所有情景，本章介绍如何使用自己的数据集对LLM进行微调，并提供实践示例和练习，让读者可以快速自定义模型。

- 第5章：深入讲解提示工程的世界，对高级策略技术的讲解可以帮助读者从LLM中获得更多的高级策略和技术，例如，输出验证和语义小样学习。

- 第6章：通过微调基于OpenAI的推荐引擎，介绍如何修改模型体系结构和嵌入，以更好地适应用户的特定用例和需求，调整LLM架构以满足用户的需求。



**第3部分：大模型的高级应用**

- 第7章：讲解下一代模型和体系结构，它们正在突破LLM的极限。本章将组合多个LLM，并使用PyTorch建立一个框架来构建自定义的LLM架构。本章还介绍从反馈中进行强化学习，以使LLM符合用户的需求。

- 第8章：提供微调高级开源LLM的实践指南和示例，重点是实现。本章不仅使用通用语言建模，还使用增强等高级方法来微调LLM，并从反馈中学习，创建自己的LLM-SAWYER。

- 第9章：讲解在生产环境中部署LLM的实际注意事项，如何扩展模型，处理实时请求，并确保模型稳健可靠。



**第4部分：附录**

3个附录包括常见问题列表、术语表和LLM应用的参考。

- 附录A：作为一名顾问、工程师和教师，笔者每天都会收到很多关于LLM的问题，此处整理了一些较有影响力的问题。

- 附录B：术语表提供本书中一些主要术语的参考。

- 附录C：本书使用LLM构建了许多应用程序，附录C旨在为那些想要构建自己的应用程序的读者提供一个起点。对于LLM的一些常见应用，本附录将建议关注哪种LLM，以及可能需要的数据，还有可能会遇到的常见陷阱以及如何处理。



### 本书特色

读者也许会问：“是什么让本书与众不同？”首先，笔者在这项工作中汇集了各种各样的经验：从笔者的理论数学背景，笔者进入创业世界的经历，笔者作为前大学讲师的经历，到笔者目前作为企业家、机器学习工程师和风险投资顾问的经历。每一次经历都加深了笔者对LLM的理解，笔者把所有这些知识都倾注在本书中。

读者会在本书中发现一个独一无二的特色，那就是概念在现实世界中的应用。当笔者说“现实世界”时，笔者是认真的：本书充满了实践和实践经验，可以帮助读者理解LLM在现实中的应用。

此外，本书不仅仅是关于理解当下所涉及的领域。正如笔者经常说的，LLM的世界是随时间变化的，即便如此，一些基本原理仍然是不变的，笔者在本书中强调了这些。这样读者不仅为现在做好了准备，也为未来做好了准备。

从本质上讲，本书不仅反映了笔者的知识，还反映了笔者对人工智能和LLM构建的热情。本书是笔者的经历、见解以及笔者使用LLM对广大读者的启迪。这是笔者向你发出一起探索这个迷人、快速发展的领域发出的邀请。



### 总结

这里或许是我们共同旅程的开始，这取决于你如何看待它。你已经了解了笔者是谁，以及这本书为什么存在，期待什么，以及如何充分利用它。

现在，剩下的由你决定。笔者邀请你加入进来，让自己沉浸在LLM的世界里。无论你是经验丰富的数据科学家，还是好奇的爱好者，这里都有适合你的东西。笔者鼓励你积极参与本书——运行代码，调整它，分析它，然后把它重新组合起来。探索、实验、犯错、学习。



### 致谢

**致我的家庭**：谢谢你，妈妈，你一直是我教学力量和影响的化身。是你对教育的热情让我意识到分享知识的价值，我现在努力在工作中做到这一点。爸爸，你对新技术的敏锐及其潜力的兴趣一直激励着我突破自己的领域。妹妹，你不断提醒我要考虑我的工作对人类的影响，让我脚踏实地。你们的见解使我更加意识到工作影响着人们的生活。

**致我的妻子**：对于我的生活伴侣伊丽莎白来说，当我沉浸在无数个写作和编码的夜晚时，你的耐心和理解是无价的。谢谢你忍受我的胡言乱语，帮助我理解复杂的想法。当道路看起来很模糊时，你一直是一根支柱、一个传声筒和一盏明灯。你在这段旅程中的坚定一直是我的灵感来源，否则这部作品不会是现在的样子。

**图书出版流程**：衷心感谢Debra Williams Cauley为我提供了为AI和LLM社区做贡献的机会。在这个过程中，我作为一名教育工作者和作家，所经历的成长是不可估量的。因为迷失于大模型的复杂的微调过程，耽误了本书的出版时间，对此深表歉意。我还要感谢Jon Krohn的推荐，感谢他一直以来的支持。 
