标签(在例子中,要么是0,要么是1)的元组。然后可以优化开源嵌入,并尝试不同
的上下文长度超参数(图6.7)。


![image](https://github.com/user-attachments/assets/b0eb5b6e-c729-4750-9cb5-91a23984fccb)



图6.7中,Jaccard分数被转换为余弦相似度标签,然后输入到双编码器中,使

双编码器能够尝试学习生成的动漫描述之间的模式,以及用户如何喜欢共同的
标题。

当得到动漫对之间的Jaccard相似度后,可以通过应用一个简单的规则将这些
分数转换为双编码器的标签。在本例中,如果分数大于0.3,那么标记为“正”(标
签1),如果小于0.1,标记为“负”(标签0)。

### 调整模型架构
在使用开源嵌入时,可以在必要时更灵活地更改和调整模型结构。例如,在本
案例研究中使用的开源模型经过预训练,一次只能接受128个词元,并截断任何超
过这个长度的词元。图6.8显示了生成动漫描述的词元长度直方图。显然,有很
多描述超过了128个词元,在600个词元范围内。


![image](https://github.com/user-attachments/assets/4fda17e0-889b-4886-9d6c-7cbaa0b77283)


图6.8中,在词元化之后,有几部动漫有几百个词元那么长,有些甚至超过600
个词元。
在程序列表6.3中,将输入序列长度从128更改为384。
**程序清单6.3：修改开源双编码器的最大序列长度**
```python
from sentence_transformers import SentenceTransformer

# 加载预训练SBERT模型
model = SentenceTransformer('paraphrase - distilroberta - base - v1')
model.max_seq_length = 384  # 将长文档截断为384个词元
model
```
为什么选择384？词元长度直方图(图6.8)显示,384将完整捕获大部分动漫,
并截断其余部分。384 = 2⁸ + 2⁷,是两个2的指数之和,现代硬件组件,特别是图形
处理单元(GPU),一般以2的指数为最佳性能参数,因为这样它们可以均匀地分配
工作负载。


那么为什么不使用512,以捕获更多的训练数据呢？因为增加词元窗口还是
需要谨慎操作的。增加的词元窗口大小越大,推荐引擎所需的训练数据就越多,因
为扩增维度后模型的参数也变大了,因此有更多的东西需要学习。加载、运行和更
新更大的模型也需要更多的时间和计算资源。

为了验证512维嵌入向量的可行性,最初尝试了512维的嵌入器,但是结果并
不好,并且耗时也超过了20%。

明确地说,无论以任何方式修改原始的预训练基础模型,模型都必须从头开始
学习。在这种情况下,模型将从零开始学习长度超过128个词元的文本,以及如何
在较长的文本窗口上分配注意力得分。调整这些模型架构可能很困难,但从模型
效果的角度来看通常是值得的。在本例子中,将最大输入长度更改为384只是开
始,因为该模型现在必须学习长度超过128个词元的文本。

现在已经修改双编码器架构,数据也准备就绪,下面开始进行模型微调。

### 6.1.7 使用Sentence Transformers微调开源嵌入器

现在开始使用Sentence Transformers来微调开源嵌入器,Sentence Transformers
是建立在Hugging Face Transformers上的一个库。

首先使用Sentence Transformers库创建自定义训练,如程序清单6.4所示。
这里使用库中提供的训练和评估功能,例如用于训练的fit()方法和用于验证的
evaluate()方法。
**程序清单6.4：微调双编码器**
```python
# 为训练实例创建DataLoader
train_dataloader = DataLoader(
    train_examples,
    batch_size=16,
    shuffle=True
)

# 为验证实例创建DataLoader
val_dataloader = DataLoader(
    all_examples_val,
    batch_size=16,
    shuffle=True
)

# 使用句子转换器的余弦相似度损失
loss = losses.CosineSimilarityLoss(model = model)

# 设置训练周期
num_epochs = 5

# 使用10%的训练数据进行热身
warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)

# 使用验证数据创建评估器
evaluator = evaluation.EmbeddingSimilarityEvaluator(
    val_sentences1,  # 每对验证数据中第一个动画描述列表
    val_sentences2,  # 每对验证数据中第二个动画描述列表
    val_scores  # 验证数据的余弦相似度标签列表
)

# 得到最初的指标
model.evaluate(evaluator)  # 初始化向量相似度分数: 0.0202

# 配置训练过程
model.fit(
    # 根据训练数据和损失函数设置训练目标
    train_objectives = [(train_dataloader, loss)],
    epochs = num_epochs,  # 设置训练轮数
    warmup_steps = warmup_steps,  # 设置热身步数
    evaluator = evaluator,  # 设置训练期间的验证评估器
    output_path = "anime_encoder"  # 为存储微调模型设置输出口径
)

# 得到最后的指标
model.evaluate(evaluator)  # 最后的相似度分数: 0.8628
```

在开始微调之前,需要确认几个超参数,如学习率、批量大小和训练轮数。通
过尝试各种超参数设置,以找到一个能带来最佳模型性能的最优组合。第8章将
讲解几十个开源微调超参数——如果读者想更深入地了解笔者是如何得出这些参
数的值,请参考第8章。

这里通过检查余弦相似度的变化来衡量模型的学习效果,在训练后,会跃升至
0.8和0.9的高位。

通过微调的双编码器可以为新的动漫描述生成嵌入,并将其与现有的动漫嵌
入进行比较。通过计算嵌入之间的余弦相似度,可以推荐与用户偏好最相似的
动漫。


一旦使用用户偏好数据微调单个自定义嵌入器,就可以相对容易地替换具有
相似架构的不同模型,并运行相同的代码,从而快速扩展嵌入器选项。对于这个案
例研究,笔者还微调了另一个名为all - mpnet - basev2的LLM,它被认为是一个非常
好的以开源语义搜索为目的的嵌入器。它也是一个双编码器,因此可以简单地用
mpnet替换RoBERTa模型的调用,几乎不需要更改代码。

### 6.1.8 微调效果总结
在本次案例研究中,包含以下几个任务。

**任务1**：使用原始数据集中的几个原始字段生成自定义动漫描述字段。

**任务2**：使用NPS/Jaccard评分的用户动漫评级和模型生成的描述文字两类
数据来训练双编码器。

**任务3**：修改开源架构模型,以接受更大的词元窗口,适应更长的描述字段。

**任务4**：使用训练数据微调两个双编码器,以创建一个将描述映射到更符合用
户偏好的嵌入空间的模型。

**任务5**：使用NPS评分定义一个评估系统,以奖励系统推荐出用户喜欢的动
漫(即用户在测试集中给动漫打9分或10分),并惩罚系统推荐出用户不太喜欢的
动漫(即用户在测试集中给动漫打1~6分)。

1. **四个候选的嵌入器**

(1) text - embedding - 002：OpenAI推荐的适用于通用任务的嵌入器,主要针
对语义相似性进行了优化。

(2) paraphrase - distilroberta - base - v1：一个开源模型,经过预训练,可以总结
短篇文本,无须微调。

(3) anime_encoder：在 ** paraphrase - distilroberta - base - v1 ** 模型的基础上,
增加嵌入层维度至384个词元窗口,并根据用户偏好数据对模型进行微调。

(4) anime_encoder_bigger：一个更大的开源模型(all - mpnet - base - v2),使用
512个词元的窗口进行预训练,笔者根据用户的偏好数据进行进一步微调,方法和
数据与anime_encoder相同。


图6.9展示了四个候选嵌入器在扩大推荐窗口(即向用户展示多少个推荐)的
最终结果。


![image](https://github.com/user-attachments/assets/4775420f-e343-454e-be44-d982724a556e)


图6.9中x轴上的每个刻度表示向用户展示动漫标题的列表。y轴是使用前
面讲述的评分系统的嵌入器的汇总得分,如果正确的推荐被放置在列表的前面,还
会进一步奖励该模型,如果用户不喜欢的动漫被放置在列表的开头,也会惩罚该
模型。


图6.9中,更大型的开源模型(anime_encoder_bigger)在根据历史偏好向用户
推荐动漫标题方面的表现一直优于OpenAI的嵌入模型。



2. **一些有趣的点**


(1) 表现最好的模型是较大的微调模型。它在向用户提供用户喜欢的推荐方
面始终优于OpenAI的嵌入器。


(2) 微调后的distilroberta模型( ** anime_encoder ** )的性能不如其预训练
的基础模型(base distilroberta),后者一次只能接收128个词元。出现这一结果最
有可能的原因是：该模型的注意力层没有足够的参数来很好地捕捉推荐问题,而
且它的非微调基础模型只是依赖于推荐语义上相似的标题；该模型可能需要超过
384个词元来捕获所有可能的关系。


(3) 随着推荐电影个数的增多,所有模型推荐的电影质量是下降的。随着推
荐电影的增多,推荐列表中的电影的置信度越来越低。


3. **探索与利用**


推荐系统的“探索”水平可以定义为推荐用户尚未观看过的内容的频率。我们
没有采取任何明确的措施来鼓励嵌入器进行探索,但仍然值得看看它们表现如何。
图6.10显示了测试数据集中推荐给所有用户的动漫原始数量的图表。


![image](https://github.com/user-attachments/assets/476b9610-d03c-448d-be62-405882c16814)


OpenAI的Ada和较大的微调编码器产生的推荐比其他两个编码器更多,但


OpenAI在推荐独特动漫的多样性方面似乎处于领先地位。这可能是一个现象,
表明用户不是特别具有探索性,倾向于选择相同的动漫,而且经过微调的双编码器
正在捕捉这种行为,并提供更少的新颖结果。也可能OpenAI的Ada嵌入器是在
如此多样化的数据集上训练的,并且参数如此之大,以至于它在提供一致偏好的动
漫方面比微调模型更好。


为了回答这些问题和其他问题,需要进一步研究测试。例如,①尝试新的开源
模型和闭源模型。②设计新的质量保证指标,以更全面的指标测试嵌入器的效果。
③使用相关性系数等其他指标而不是Jaccard相似性得分来计算新的训练数据集。
④改变推荐系统超参数,例如k。目前案例中只考虑为每个推荐的动漫抓取前k =
3个动漫——改变这个数字呢？⑤在博客和维基百科上对动漫推荐理论进行
一些预训练,这样模型就可以潜在地获取一些关于如何考虑推荐的信息。


最后一个想法有点“不切实际”,如果我们能把它与另一个大模型上的思维链
提示结合起来,效果会更好。即便如此,这是一个大问题,有时意味着需要大胆的
想法和大胆的答案,所以笔者现在把它留给读者——去发掘更多的想法吧。

### 6.2 本章小结
本章介绍了针对特定任务微调开源嵌入模型的过程,该任务基于用户的历史
偏好生成高质量的动漫推荐。将定制的嵌入模型与OpenAI的嵌入器的性能进行比
较,观察到微调后的模型可以始终优于OpenAI的嵌入器。


为特定任务定制嵌入层及其架构可以提高性能,并为闭源模型提供可行的替
代方案,特别是在可以访问词元数据和利用资源进行实验的情况下。本章中模型
的微调在推荐动漫标题方面的成功证明了开源模型的强大功能和灵活性,为读者
在其他任务中的进一步探索、实验和应用铺平了道路。 
