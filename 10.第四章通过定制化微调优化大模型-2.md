### 程序清单4.2：进行第一次微调调用
```
# 使用OpenAI的API提取‘fine_tunes.create’命令
!openai api fine_tunes.create \
    # 以JSONL格式指定训练数据集文件
    -t "amazon - english - full - train - sentiment.jsonl" \
    # 以JSONL格式验证训练数据集文件
    -v "amazon - english - full - val - sentiment.jsonl" \
    # 微调后打开分类尺标计算
    --compute_classification_metrics \
    # 设置分类数目(此例子中为5)
    --classification_n_classes 5 \
    # 指定用于微调的基础模型(使用最小的模型ada)
    -m ada \
    # 设置训练的周期数(此例子中为1)
    --n_epochs 1
```
### 4.6.1 采用量化指标评测大模型

衡量微调模型的性能对于理解其有效性并找出提升空间至关重要。利用精度、F1分数或困惑度等指标和基准可定量衡量模型性能。除了定量指标外，定性评估技术，如人工评估和分析样本输出，可以提供有关模型优缺点的宝贵见解，帮助确定可以进行进一步微调的方向。

如图4.6所示，模型经过一次迭代后，在经过去重和打散的训练数据上表现良好。在1个周期之后，分类器在预留的测试集上的准确率超过63%。测试集没有提供给OpenAI；相反，我们将其保留用于最终模型的比较。

![image](https://github.com/user-attachments/assets/c7e547d5-c5c4-4871-83e5-993b5e5569fd)


63%的准确率可能听起来很低，但预测打分的精准值很困难，因为人们在写的内容和最终评估产品方面并不总是保持一致。所以笔者提供以下两个额外的指标。

- 将准确率计算放宽为二进制(模型预测了3分或者以下，并且评论实际上是3分或者以下)，相当于准确率为92%，这意味着模型可以区分“好”和“坏”。

- 将计算放宽为one-off，例如，如果实际评级是1星、2星或3星，则预测2星的模型将被视为正确，相当于准确率为93%。

所以预测准确率还不错。分类器肯定正在学习好与坏之间的区别。下一个合乎逻辑的想法可能是“让我们继续训练吧”，因为我们只训练了1个周期，所以训练更多的周期一定更好，对吧？

使用更小的步长，更多的训练步数或者周期，使用新标记的数据进行训练，或者更新已经微调好的模型，这个过程称为增量学习，也称为连续学习或在线学习。增量学习通常会产生更可控的学习效果，这在处理较小的数据集或想要保留模型的通识时是理想的方案。读者可以尝试一些增量学习。我们将使用已经微调过的Ada模型，让它对相同的数据再运行3个训练周期。结果如图4.7所示。在一个成功的训练周期后，在接下来的3个增量学习训练周期中，模型的性能看起来几乎没有变化。4倍的成本却只带来1.02倍的性能提升。


![image](https://github.com/user-attachments/assets/8324034f-d241-4594-8b4e-1b82e12980af)


更多的周期似乎并没有起到任何效果。但在对语料测试数据集进行测试并将其与第一个模型进行比较之前，一切都没有定论。表4.1显示了结果。



|定量测量（适用于测试集）|1个训练周期情绪分类：未打散数据|1个训练周期情绪分类：打散数据|4个训练周期情绪分类：打散数据|
| ---- | ---- | ---- | ---- |
|准确率|32%|63%|64%|
|好对坏|70%|92%|92%|
|一次性准确率|71%|93%|93%|
|微调的花费|$4.42|$4.42|$17.68|

所以，我们付出4倍的价格，换来的只是准确度提高了一个百分点？在笔者看来，这并不值得，但也许对某些人来说是值得的。有些行业要求模型近乎完美，一个百分点的差异都很重要。笔者将决定权交给读者，同时说明，一般来说更多的周期并不总是带来更好的结果。增量/在线学习可以帮助用户找到正确的停止点，但需要付出更多的前期努力，但从长远来看，这是值得的。



![image](https://github.com/user-attachments/assets/cf5952b1-c26f-4f34-8778-0d2534791472)


### 4.6.2 定性评估技术
当与定量指标一起使用时，定性评估技术为微调模型的优缺点提供了有价值的见解。检查生成的效果并使用人工评估好坏，可以确定模型擅长或不擅长的方向，进而指导未来的微调工作。

例如，可以通过查看在playground上预测第一个词元的概率，如图4.8所示，GPT - 3模型的playground和API(包括我们的微调Ada模型)提供了可以用来检查模型对特定分类的置信度。请注意，主选项是“1”，前面有一个空格，就像在我们的训练数据中一样，但列表顶部的一个词元是“1”没有前导空格。根据许多LLM的观点，这是两个独立的词元——这就是为什么笔者经常强调这种区别。因为很容易忘记和混淆它们。或通过API的logprobs值(程序清单4.3)来获得分类的概率。


![image](https://github.com/user-attachments/assets/6efadef4-624d-4e7b-a477-2fee05243f2b)


### 程序清单4.3：从OpenAI API获取词元分布
```python
import math
# 从test数据集中选择一个随机的提示
prompt = english_test_df['prompt'].sample(1).iloc[0]

# 用微调后的模型生成一个Completion
res = openai.Completion.create(
    model = 'ada:ft - personal - 2023 - 03 - 31 - 05 - 30 - 46',
    prompt = prompt,
    max_tokens = 1,
    temperature = 0,
    logprobs = 5
)

# 初始化一个空列表来存储概率
probs = []
# 从API回复中提取logprobs
logprobs = res['choices'][0]['logprobs']['top_logprobs']
# 把logprobs转换为概率并存储在'probs'列表中
for logprob in logprobs:
    _probs = {}
    for key, value in logprob.items():
        _probs[key] = math.exp(value)
    probs.append(_probs)
# 从API回复中提取预测的分类
pred = res['choices'][0].text.strip()
# 输出提示、预测的分类和概率
print("prompt:")
print(prompt[:200], ",,,\n")
print("predicted star:", pred)
print("probabilities:")
for prob in probs:
    for key, value in sorted(prob.items(), key = lambda x: x[1], reverse = True):
        print(f"{key}: {value:.4f}") 
```
### Output:
```
Prompt:
Great pieces of jewelry for the price
Great pieces of jewelry for the price. The 6mm is perfect for my tragus piercing. I gave four stars because I already lost one because it fell out! Other than that I am very happy with the purchase!
Predicted Star: 4
Probabilities:
4: 0.9831
5: 0.0165
3: 0.0002
2: 0.0001
1: 0.0001
```
在定量和定性评测之后，假设模型已经准备好投入生产，或者至少是在构建中，或者处于即将测试的环境，就可以着手将新模型整合到应用程序中。

### 4.6.3 将微调的GPT - 3模型集成到应用程序中

将微调后的GPT - 3模型集成到用户的应用程序中，与使用OpenAI提供的基础模型完全相同。主要区别在于，在进行API调用时，用户需要引用经过微调的模型的唯一标识符，以下是应遵循的关键步骤。

1. **识别微调模型**：完成微调过程后，用户将收到一个用于微调模型的唯一标识符，例如“ada:ft - personal - 2023 - 03 - 31 - 05 - 30 - 46”。请务必注意此标识符，因为API调用需要用到此标识符。

2. **正常使用OpenAI API**：使用自己的OpenAI API向微调模型发出请求。在提出请求时，请将基础模型的名称替换为自己的微调模型的唯一标识符。程序清单4.3提供了这样的示例。 

3. **调整任何应用程序逻辑**：由于微调模型可能需要不同的提示结构或生成不同的输出格式，用户可能需要更新应用程序的逻辑来处理这些变化。例如，在提示中，可以将评论标题与正文连接起来，并添加自定义后缀“\n\n###\n\n”。 

4. **监控和性能评估**：持续监控微调模型性能并收集其他用户的反馈。可能需要使用更多数据迭代微调模型，以提高其准确性和有效性。 

### 4.6.4 案例学习：亚马逊评论分类
现在已经成功地对Ada模型进行了微调，使其适用于情感分类等相对简单的样本，下面尝试解决更具挑战性的任务。在第二个案例研究中，将探索如何微调GPT - 3模型，以提高它在来自同一数据集的亚马逊评论分类任务中的表现。该任务根据评论的标题和正文将亚马逊产品的评论分类到各自的产品类别中，就像我们对情感分类任务所做的那样。但是，不再只有5个类别，而是有31个不平衡的类别。如图4.9所示，有31个独立的类别可供选择，并且类别分布非常不平衡。这是造成分类任务困难的主要原因。

更困难的分类任务揭示了许多与机器学习相关的隐藏困难，例如处理不平衡数据和定义不明确的数据——类别之间的区别微妙或模糊。在这些情况下，模型可能难以辨别正确的类别。为了提高性能，可以考虑精炼问题定义，删除冗余或混淆的训练样本，合并相似的类别，或通过提示词向模型提供额外的上下文。读者可以在本书的代码库中查看所有这些工作。


![image](https://github.com/user-attachments/assets/12781648-d71e-467f-b560-5339d93023fb)


### 4.7 本章小结
微调GPT - 3等LLM是提高其在特定任务或领域性能的有效方法。通过将微调模型集成到自己的应用程序中并遵循最佳部署实践，就可以得到更高效、准确和成本效益更高的语言处理解决方案。持续监控和评估模型的性能，并通过迭代微调来确保其满足应用程序和用户不断发展的需求。

后面的章节中将用一些更复杂的例子讲解微调的想法，同时探索开源模型的微调策略，以进一步降低成本。 
